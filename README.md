# SPX
### SuperPositioning Text to Font &amp; Entangling to a CxHC Datagraphs
<hr></br></br>
&nbsp; &nbsp; &nbsp; As we make our way into a more data-driven world it's time the data drive the processes. This is the concept of storing data differently where we can have "dumb data" and "smart data". At the moment, if you want something like 'smart data' you would need to run an API structure along side the data. Encrypting these together has been the method used but what if we could only store 1% of the actual data to store with the API, that could medigate encrypting and allow for simpler prcesses like CRC encoding. Very quickly we went from storing the data with padding in a method to make decrypting difficult to encoding part of the data with padding in a method to make data-determation more difficult.</br>
</br>
<h1 style='align:center;text-align:center;'><b>Determinable Mixed Binary Encoding</b></h1>
</br></br>
&nbsp; &nbsp; &nbsp; Cryptocurrency and hash mixers have shown that mixing data in a determinist way can add trustlessness into systems that normally would requrie large amounts of trust. The data we type into text fields may sometimesbe important but yet will have no problem having insecure & plain-text input fields. The time has come to increase the security of user data to help the integrity of the quickly qrowing <i>soft-lined digital world</i>.
</br>&nbsp; &nbsp; &nbsp; Mixing binary through faux-superpositioning before recoding state changes should increase probable security by magnitudes greater in comparision to other reversable hashes used online like Base64 & Base58. Taking the encoding a bit further utilizing a flexible procedural way to determine dynamically-modular grid-based shapes, we can increase the natural security to similar methods of lattice encryptions. Tapping into fuax-quantum mechanics again to superposition APIs and marker-codes as parity checks can both direct the use of the data as intended while increasing it's own entropy. Using generic structred standards for the modular-capable internal systems of the algorithm should create stronger obscurity by allowing different types of superpositions for the same encoding standards.
<h3><sub><sup>[<sub><i>ASTRACT</i></sub>]</sup></sub></h3>
&nbsp; &nbsp; &nbsp; My hypothesis is that encoding can be used to have fast-hook swapping of plain text to encode text trustlessly & potentially on the fly. Limiting the shape possibiliites while using a "<b>Talk Model</b> inspired by hit TV show "<i>Full House</i>", we can creae determinable flexible superpositioning while the generic model will encode/decode all the same. Using the "<i>Futurama Theorem</i>" (<a href='https://en.wikipedia.org/wiki/The_Prisoner_of_Benda#The_theorem' target='_blank' rel='noopener noreferrer'><b>Ken Keeler, <i>2010</i></b></a>) to self-correct the <i>talk model</i> during both encoding and decoding regardless of swappable parts of the algorithm to help ensure reversibility. Additionally, using a modified version of the Futurama Theorem equation to perform new parity check methods to help find and correct potentially multiple errors with as little as a single binary bit.
</br></br>
<h1 style='align:center;text-align:center;'><b>Full House Talk Model</b> <sub><sup>[<sub><i>CONCEPT</i></sub>]</sup></sub></h1>
</br></br>
&nbsp; &nbsp; &nbsp; In the classic American TV sitcom, "<b>Full House</b>" (<a href='https://www.imdb.com/title/tt0092359/' target='_blank' rel='noopener noreferrer'><b>TV series 1987-1995, IMDB</b></a>) when the Tanner family has a visit form their eldest daughter's firend, Kimmy Gibbler, she would often speak about things that only DJ understands. Stephanie, DJ's younger sister, can explain what DJ transcribes to her dad but not accurately, so Michelle (the youngest Tanner child) would be needed to fill in the gaps. In the end, the father and his cohort of male-friend-guardians are often still left unusre of what is being said, so they need the help of Becky to decode what the men have to make sense of the situation. In the show this made a great dynamic that showed how differently generations speak because of the influences of their own sub-cultures of school, family, situations of life & public media.</br>
&nbsp; &nbsp; &nbsp; The <i>Full House Talk Model</i> uses the idea of bait & switch with the information to make what's actually being said unclear. The <b>Futurama Theorem</b> will help keep everything aligned and settled with modular sections in the talk model & modified versions oof the theorem will be used to find-&-fix errors as well as turn anything into a single binary representation for new parity checks. Hopefully when we are done, we'll be able to pull the full conversation from very little information just like they do on the show.</br>
&nbsp; &nbsp; &nbsp; Before diving into the algorithm, there are some world variables needing to be set. For the most part, variables of sub-functions are modular so as we introduce new sections or functions, new variables may arise & some may decay. Depending on the location of the algorithm you may or may not have some data to rely upon so once the coupling or decoupling starts, you cannot revert beyond that function's section. All instructable data should allow the recommendation for user's to input their modular data like instructions and instructables via Wave-Data H-APIs or CID pulling from IPFS. Modular function's variables are called instructions while modular function's are called instructables (list of instructions and their variables). Instructables help allow for any-input with standard output but most importantly this allows for customization to the algorithm as needed.</br>
&nbsp; &nbsp; &nbsp; The Full House Talk Model's base for encoding is to superposition the input to a font designed to be "visually encrypted" called Node. This means the the data we are switching the user keycodes for are keycodes of an end-2-end encrypting font. This is the first step and the first consideration because the faster we can drop what the user actually typed, the better. Once we swap the user input for Node keycodes we also wipe the input and replace it with random gibberish of similar lengths to the input to give the impression that what is being seen may be what's being typed. Throughout the entire process of this algorithm, we will be doing tiny extra steps for var ious reasons with the biggest consideration being but definitely not the only consideration to allow for confusing power consumption to prevent power-light-decoupling nor power-light-decoding which is the act of decoding functions from watching a power-light flicker or watching the power volts/amps/watts change in the power cord of the computing device.
</br></br>
<h1 style='align:center;text-align:center;'><b>Compounding Extended Hamming Code (<i>CxHC</i>)</b> <sub><sup>[<sub><i>ALGORITHM</i></sub>]</sup></sub></h1>
</br></br>
&nbsp; &nbsp; &nbsp; When an input is being read and swapped, we need to load a few variables with data. variables for each child amoung the processes we'll need throughout this part of the algorithm. This information will need to be set or the input should use a standard instructable set.</br>
&nbsp; &nbsp; &nbsp; When swapping the input for what Kimmy said, that is going to store the character via Node font, which in turn is what DJ says. The input swap records the Node shape based on what DJ says, places the shape on a centered 17-slot graph then records the positioning of that character to this graph. If the character physically has nodes in the first row, second row, third row or under-table slot this will change what Node keycodes will be pushed through the algorithm. How the shape appears on the graph will determine what Steph (Stephanie) & Michelle says. The instructable for this part of the algorithm (when Kimmy talks to DJ then to the younger siblings) will define what DJ, Steph & Michelle says based on either the keycode or Latin-character input. DJ & Michelle only change what they say per character inputted while Steph adds the new input to what she said last, assuming she started with a blank slate before Kimmy started talking.</br>
&nbsp; &nbsp; &nbsp; The algorithm has to re-center the null-slot or under-table of the font superpositioning graph with every input. This is the first use of the Futurama Theorem [trunc|_(3.14*n)+2_|]. In this case, we swap "n" for "z" for 'z' is the length of what Steph said altogether and one of the best ways to determine internal length of our superposition. The internal data length or how many characters are stored is important but something that can be a lattice or matrix instead. The internal data length can be a number, hexdec, hash or formula based on how much information you need to hide. The standard is to just base everything on Steph's memory of length since she's the only one keeping count.</br>
&nbsp; &nbsp; &nbsp; The superpositioning graph has a unique ordinal system. We will end up with what's basically Compounding Extended Hamming Code (CxHC) so the hidden superpositioning graph uses separated ordinals to not interfere with the other graph ordinal systetm. The superpositioning graph is ordered vertically 1,2,3,4 but horizontally just add a 0 per horizontal right shift. In Example: 1, 10, 100, 1000, 2, 20, 200, 2000; so each row is just 1-4 then the further to the right, the more zeros behind it. The standard code graph setup (like for Hamming Code) is in binary, ie: 0, 1, 10, 11, 100, 101, 110, 111, 1000. The noticeable difference being the superpositioning graph isn't binary capable but if we put the slot number into binary (0-16), we get that same ordinal design for pin-pointing errors for correcting them.</br>
&nbsp; &nbsp; &nbsp; The other aspect of the superpositioning is, when we look at the node placements on the superpositioning graph (per character). If the node has left-to-right objects in succession, the line indentifier will increase for each left-to-right (horizontal) succession. In example if the node is 3 objects long on the x-axis it may be remembered by Michelle as 111 or 333, depending on which line it lands on. If the node has top-to-bottom objects the sums going furthest top to just below to just below, never going beyond 3 addics per section. This unique approach to superpositioning does take unique shaped objects to have semi-unique corresponding digits allows us to predict the total possible shapes of input which could be relayed in the superpositioning instructable.</br>
&nbsp; &nbsp; &nbsp; By having a soft cap of 3-successional allowances for combining forces sets a finite number of possible shapes based on complexity. To expand this, simply expand the number of successional allowances in any or all directions (vertical, horitontal; connections). Setting directional commands for how successional-allowances are designed instead of a successional cap would be a lattice stylized encoding. The limitations of allowances are based on the shape instructables, all overly-large shapes for a determined instructable may cause a fail error, phantom characters (multiple unwanted characters in place of a single wanted character), or incomplete decoding/encoding. If an encoder is customized or finely tuned outside the common or standard, it should encompass a decoder within the same service, product, website, etc so that they feel as if two sides of the same coin. Standard outputs should be marked somewhere on the website or near the input/output areas with the standard version number. Examples of version number possibilities may be but certiantly not limited to the following: SPX Standards:: v1, v2, v3 (versionNUMBER) or Pulled Standards (imported):: IPFSv1, IBSv2, NNNv1 (LOCATIONversionNUMBER). Wave-Data H-APIs should be used for transmission of importable data including for instructables like version standards rather it be to insert-into a de/encoder or to grab-from a de/encoder.</br></br>
&nbsp; &nbsp; &nbsp; Begin cutting what Steph said to place the binary representation into the superpositioning graph. Using the mathematical symbols in order of left-to-right will be the way to superpositioning. Use a turning-counter machine principle to keep track of the data.</br>
&nbsp; &nbsp; &nbsp; We read via the turning machine, checking first the read position. Based on what's read move forward or backward to read again. Then based on what's there, repeat or write to the counting machine's slot. When the turning finished it's loops or the turning machine wrote in a slot then the counter machine moved forward one to a now empty slot, reset the turning machine to the new position equal to the counter machine's newest position. So the counter machine is to determine the location of the read/write process while the turning machine does more intricate work then finally when both machines agree & something is recorded by the counter machine the next slot is moved so the entire process restarts again.</br>
&nbsp; &nbsp; &nbsp; Once we have the array of the 4 rows of the superpositioning graph, we can reset the turning-counter machine to now write the state changes of the row objects. Start at the null-position of all the row-tapes, record the first object seen in each row with the turning machine. Once done, move the counter machine one, then check each row with the turning machine recording if is the same as before (1) or different as before (0) per row's object. This means the sequence "1001" would be recorded as "1010". Each row is treated individually to the other rows, but all four rows are checked per loop cycle, if a row's length has been met, check it's length then rest. If rest happens, this will look like multiple processes are being performed. Once the counter machine reaches the end of the longest row-tape, end the loop cycle or use an escape value to end the loop cycle.</br>
&nbsp; &nbsp; &nbsp; Graphs are to be made every 45 characters (standard), every 255-bytes or 175 characters (big-block), when a special 'finalize graph' button is pressed (manual), when the "enter" or "return" keycode is seen by Kimmy (dynamic). Which is used is up to the generator but may be to fit specific databases or situations. When we get to the point of finalizing a graph or subgraph, we need to perform the wrapping protocol. Wrapping the graph is fairly easy. The state-change is recorded and ready so we need to check the algorithm's current state-size to build it's mapping hash. If it's a subgraph it will have a directory key instead but this process is done regardless & the algorithm will record the mapping hash data as the Program 1 slot of the final graph. We need to run parity checks to set our determiner slots next.</br></br>
&nbsp; &nbsp; &nbsp; This system allows for a multitude of ways to do parity checks so we will go over the some possible parity checks. A parity check is determining if data was changed. Parity checks in the manner we are looking at are very common in (7,4) Hamming Code but for what we are doing, we are not checking to see if the binary of the state change rows were changed. This will tell the decoder how to tell if the binary of the data has any possible errors and possible corrections. Because we are not directly working with only binary, we can use the determiner slots to drop almost any data ie: the total-byte size of the end datagraph, encode hard-error-detection markers, apply trinary computational actions, entangle data identifiers, entangle API markers or nearly anything else with Data-Wave H-APIs.</br>
&nbsp; &nbsp; &nbsp; The most common way to parity check is the 7,4 Hamming code method of checking specific row associations to cross-check the entirety of the datagraph. 7,4 Hamming code looks at 2 rows/columns at a time per parity check slot. 1st parity slot checks columns 2 & 4, place a 0 or 1 in D1 to ensure this check has an even number of ones. 2cd parity slot checks columns 3 & 4, place a 0 or 1 in D2 to ensure this check has an even number of ones. 3rd parity slot checks rows 2 & 4, place a 0 or 1 in D3 to ensure this check has an even number of ones. 4th parity slot checks rows 3 & 4, place a 0 or 1 in D4 to ensure this check has an even number of ones. Using trinary actions would allow you to use also a "2" in each D-slot to say that at that point, with the '2' being a '1' as well, there is an even number of the ones in the entire graph.</br>
&nbsp; &nbsp; &nbsp; The alternative parity check method is the 11,1 Determinless method that is using the D-slots for any value with bases higher than 3 (integers over "2", decimals, binary, Trinary, or any numerical-digit-representation of non-numerical objects) but does the parity checks by running any non-binary data through a Modified Futurama Theorem [Ceiling|^Trunc_(Trunc|_(n*3.14)_|+z)_|%2^|] and using the MFT output for the parity check. This method can still read parity checks in the method of row association checking number of ones to create dynamically-modular or ruggedly-singular checks which may include but are not limited to the following: Find Errors, Correct Errors, Mutate Data, Layer Data, Lattice-fill (quantum resistance), fast-verifications.</br>
&nbsp; &nbsp; &nbsp; It's the Modified Futurama Theorem that allows for dynamic determining slots because it turns any decimal or binary representation of what we give it into a single binary bit. Placing the data as a whole input for 'n' as it's decimal form and it's length as z we can help ensure we reliably get the same output for the same inputs. Recording the result of the parity check goes into the null position at the end as a non-numerical character that ensures the number of ones for the parity check type has an equal number of ones. Every time this recording needs to whappen after the inital time, we store the new 0 or 1 parity check bit as a variable instead of changing the actual recorded bit. Changing the variabled-bit with each loop in the pattern. Once the parity sequence is done the ending variable parity bit should be the same as the initial recorded parity bit. So, re-perform the inital recorded parity check to ensure the inital needed bit is the same as the final recorded bit. A+B=1;C+D=x;E+F=y;G+H=z;A+B+[...}+H=(A+B);</br>
&nbsp; &nbsp; &nbsp; The wrapper is just about ready. We use an ABI (Aplication Binary Interface) to display what type of data the wrapper application process needs. If you don't have the data for a particular section, just send a null-state for that section otherwise if it says, "anything" then other than empty data slots any form of data may be used. If a part of the wrapper needs a specific point of data to relay, it'll give the type of data and the way it should be displayed. Now we mix in the final values of our header ABI, which is as follows:</br>
<code><ul>datagraph {
<ul>Graphhash [
<ul>avg loop cycle (numerical; decimal preferred);
"x";
internal data size (numerical; decimal preferred);
"e";
chain weight (numerical; decimal preferred);
nonsensitical non-numeric parity bits (Alphabetical; obscure latin-characters preferred)</ul>
 ],
Determiner slot 1 [
<ul>anything</ul>
 ],
Determiner slot 2 [
<ul>anything</ul>
 ],
Programming slot 1 [
<ul>anything</ul>
 ],
Determiner slot 3 [
<ul>anything</ul>
 ],
Row 1 [
<ul>anything;
anything;
anything</ul>
 ],
Determiner slot 4 [
<ul>anything</ul>
 ],
Row 2 [
<ul>anything;
anything;
anything</ul>
 ],
Programming slot 2 [
<ul>anything</ul>
 ],
Row 3 [
<ul>anything;
anything;
anything
<ul>"."
nullstop
<ul>Row 0 [
<ul>anything
 </ul>] </ul>], </ul>}</ul></ul></ul></code></br></br>
&nbsp; &nbsp; &nbsp; Once the wrapper is finished we can send that graph and set of subgraphs when we are ready, on the fly or whenever & however the system or users chooses to. These graphs and subgraphs are designed around keeping the data intact within the specified order to ensure the data is reversable. Going as far as being able to drop the parity bits to clean-up and reduce buffer-data per block of data or datagraph only gives more options.</br>
&nbsp; &nbsp; &nbsp; Using the Modified Futurama Theorem to turn any data into a parity check does open up more potential of oppritunities but in the same way that modified maths formula gives us provability without prior knowledge. These are Minimal-Knowledge Proofs for smart storage & smart launching data-enriched applications.</br></br>
<code>[check breakdown or <a href='https://3dd.in/SPXppr' target='_blank' rel='noreferrer noopener'>Full Tech PvtPpr (private paper)</a> for "Breaking Everything Down" & "Building Everything Back" sections]</code>
</br></br>
<h1 style='align:center;text-align:center;'><b>Finalizing the Point</b> <sub><sup>[<sub><i>CONCLUDE</i></sub>]</sup></sub></h1>
</br></br>
&nbsp; &nbsp; &nbsp; The process does seem to work and can perform the various actions, ie: SuperPositioning text on the fly, recording state changes, Parity Check using MFTv3 formula, decodable graph output. The idea for at least is a success. With more tweeking & testing more possibilities should be posible later on.</br>
&nbsp; &nbsp; &nbsp; There are still a few questions left to be answered but all the questions we directly wanted to know were answered. "Do we need to know what we are typing? [no]", "Do we need to send this data? [not now]", "Can something represent data instead [yes]", "Can this be done on the fly? [yes]". But we also made a few more discoveries along the wa for example: Can we send near dataless-data? Yes!, Can we send the data at will? Yes!, Can we interlace codes with our near dataless-data? Yes!, Can we decode our encoding, everytime? Debateable, >Can we detect, find & correct multiple errors? Debatable, Can we have single-byte parity checks? YES!, Can we have as mathematical only parity checks? YES!.</br>
&nbsp; &nbsp; &nbsp; To end this on a high note, yes my hypothesis seems to be correct or loosely verified under the best of conditions. Encoding does seem to be quick enough, even if with a complex encoding function, to handle on-the-fly encoding for most devices but is potentially strong enough to be used as supplimental data storage or reduant storage. Rather or not the modularity propsed creates more trustlessness is still to be prooven. I honestly do believe this could be a new storage design to loosen what data is being stored and where. Working with the live example and test-beds will get us to build a fully functioning version of this concept as a single webpage. But until then, you can scroll past the Appendices to try the (as of writing) Unreleased SuPosXt Alpha Encoder (Demo), near the bottom of the page.</br>
&nbsp; &nbsp; &nbsp; The previous paper link (at bottom of page) will take you to the Github for this concept which should include links to usable test-sites for it's variuos parts. Many of the informational resources mentioned are stored with IPFS/IPNS (the original decentralized storage network), so any CIDs for these should be provided on GitHub.</br></br></br>


<sup>Speacial thanks to Jake La`Doge in assiting in the self-correcting methods and directing me to the "Futurama Theorem" which ended up being the glue to getting this concept system to work dynamically.</sup>
</br></br>
<sub>Speacial Thanks to The Mota Club (on telegram) for helping in motivation and spelling corrections for this paper and concept.</sub>










